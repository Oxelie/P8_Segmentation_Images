{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9fc7cdfe",
   "metadata": {},
   "source": [
    "# Classe `ImageSegmentationDataset` pour la segmentation d'images\n",
    "\n",
    "Ce notebook détaille l'implémentation et l'utilisation de la classe `ImageSegmentationDataset`, un générateur de données avancé pour la segmentation d'images avec TensorFlow/Keras.  \n",
    "Il permet de gérer le chargement, la préparation, l'augmentation et la visualisation des données pour des tâches de segmentation sémantique."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5eab8b3",
   "metadata": {},
   "source": [
    "## 1. Définition de la classe `ImageSegmentationDataset`\n",
    "\n",
    "Nous allons définir une classe héritant de `tf.keras.utils.PyDataset` pour gérer efficacement le chargement et la préparation des données de segmentation.  \n",
    "Cette classe permet de manipuler des couples (image, masque), d'appliquer des augmentations, de gérer le mélange des données, la normalisation, le one-hot encoding, et les poids d'échantillons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90892ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import pathlib\n",
    "from typing import Optional, Union, Tuple, List, NamedTuple, Any\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import albumentations as A\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Pour la reproductibilité\n",
    "np.random.seed(314)\n",
    "tf.random.set_seed(314)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "844732d4",
   "metadata": {},
   "source": [
    "## 2. Initialisation et configuration des paramètres\n",
    "\n",
    "La méthode `__init__` initialise les chemins des images et masques, les labels, la taille des batchs, la taille cible, les options d'augmentation, de normalisation, de mélange, de one-hot encoding, et les poids d'échantillons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ea4bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageSegmentationDataset(tf.keras.utils.PyDataset):\n",
    "    \"\"\"\n",
    "    Dataset generator for image segmentation tasks.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        paths: List[Tuple[pathlib.Path, pathlib.Path]],\n",
    "        labels: List[NamedTuple],\n",
    "        batch_size: int,\n",
    "        target_size: Tuple[int, int],\n",
    "        augmentations: bool = False,\n",
    "        preview: Optional[int] = None,\n",
    "        normalize: Union[bool, str] = True,\n",
    "        shuffle: bool = True,\n",
    "        label_onehot: bool = False,\n",
    "        sample_weights: Optional[List[float]] = None,\n",
    "        **kwargs: Any,\n",
    "    ) -> None:\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "        # Chargement des chemins images/masques (avec option preview)\n",
    "        self.image_paths, self.mask_paths = self.load_img_and_mask_paths(paths, preview)\n",
    "\n",
    "        # Tables de correspondance pour les catégories\n",
    "        self.table_id2category = {label.id: label.categoryId for label in labels}\n",
    "        self.table_category2name = {label.categoryId: label.category for label in labels}\n",
    "\n",
    "        # Paramètres du dataset\n",
    "        self.batch_size = batch_size\n",
    "        self.target_size = target_size\n",
    "        self.augmentations = augmentations\n",
    "        self.normalize = normalize\n",
    "        self.shuffle = shuffle\n",
    "        self.label_onehot = label_onehot\n",
    "        self.sample_weights = sample_weights\n",
    "\n",
    "        # Pipeline d'augmentation si activé\n",
    "        if self.augmentations:\n",
    "            self.compose = A.Compose(\n",
    "                [\n",
    "                    A.HorizontalFlip(p=0.5),\n",
    "                    A.OneOf(\n",
    "                        [\n",
    "                            A.RandomBrightnessContrast(\n",
    "                                brightness_limit=0.2, contrast_limit=0.2, p=1.0\n",
    "                            ),\n",
    "                            A.HueSaturationValue(\n",
    "                                hue_shift_limit=10,\n",
    "                                sat_shift_limit=15,\n",
    "                                val_shift_limit=10,\n",
    "                                p=1.0,\n",
    "                            ),\n",
    "                        ],\n",
    "                        p=0.5,\n",
    "                    ),\n",
    "                    A.OneOf(\n",
    "                        [\n",
    "                            A.GaussianBlur(blur_limit=3, p=1.0),\n",
    "                            A.MotionBlur(blur_limit=5, p=1.0),\n",
    "                            A.OpticalDistortion(distort_limit=0.05, p=1.0),\n",
    "                        ],\n",
    "                        p=0.25,\n",
    "                    ),\n",
    "                ],\n",
    "                additional_targets={\"sample_weights\": \"mask\"}\n",
    "                if self.sample_weights is not None\n",
    "                else {},\n",
    "            )\n",
    "\n",
    "        # Mélange initial si demandé\n",
    "        if self.shuffle:\n",
    "            self.on_epoch_end()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d569a0ef",
   "metadata": {},
   "source": [
    "## 3. Chargement et découpage des chemins images/masques\n",
    "\n",
    "La méthode statique `load_img_and_mask_paths` permet de découper les tuples de chemins images/masques et de gérer l'option `preview` pour ne charger qu'un sous-ensemble des données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea543b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "    @staticmethod\n",
    "    def load_img_and_mask_paths(\n",
    "        paths: List[Tuple[pathlib.Path, pathlib.Path]], preview: Optional[int]\n",
    "    ) -> Tuple[List[pathlib.Path], List[pathlib.Path]]:\n",
    "        \"\"\"\n",
    "        Unpack tuples of image and mask paths and apply preview slicing if specified.\n",
    "        \"\"\"\n",
    "        image_paths, mask_paths = zip(*paths)\n",
    "        if len(image_paths) != len(mask_paths):\n",
    "            raise ValueError(\"Number of images and masks must be equal.\")\n",
    "        if preview is not None:\n",
    "            image_paths = image_paths[:preview]\n",
    "            mask_paths = mask_paths[:preview]\n",
    "        return list(image_paths), list(mask_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b3da33",
   "metadata": {},
   "source": [
    "## 4. Calcul du nombre de classes et d’échantillons\n",
    "\n",
    "Les propriétés `num_classes` et `num_samples` retournent respectivement le nombre de classes et d'échantillons dans le dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b24d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "    @property\n",
    "    def num_classes(self) -> int:\n",
    "        \"\"\"Retourne le nombre de classes uniques dans le dataset.\"\"\"\n",
    "        return len(set(self.table_id2category.values()))\n",
    "\n",
    "    @property\n",
    "    def num_samples(self) -> int:\n",
    "        \"\"\"Retourne le nombre total d'échantillons dans le dataset.\"\"\"\n",
    "        return len(self.image_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fe1239b",
   "metadata": {},
   "source": [
    "## 5. Chargement et prétraitement des images\n",
    "\n",
    "La méthode `load_img_to_array` charge une image RGB depuis le disque, la redimensionne à la taille cible et la normalise si demandé."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf1ec51",
   "metadata": {},
   "outputs": [],
   "source": [
    "    def load_img_to_array(self, img_path: pathlib.Path) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Charge une image, la redimensionne et la convertit en tableau numpy.\n",
    "        \"\"\"\n",
    "        img = tf.keras.utils.load_img(\n",
    "            str(img_path),\n",
    "            target_size=self.target_size,\n",
    "            color_mode=\"rgb\",\n",
    "            interpolation=\"bilinear\",\n",
    "        )\n",
    "        img_array = tf.keras.utils.img_to_array(img, dtype=np.float32)\n",
    "        return img_array / 255.0 if self.normalize else img_array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a45bd1",
   "metadata": {},
   "source": [
    "## 6. Chargement et transformation des masques\n",
    "\n",
    "La méthode `load_mask_to_array` charge un masque, le redimensionne, convertit les ids de labels en catégories, et applique éventuellement le one-hot encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2206e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "    def load_mask_to_array(self, mask_path: pathlib.Path) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Charge un masque, le redimensionne, mappe les ids vers les catégories, et applique le one-hot si demandé.\n",
    "        \"\"\"\n",
    "        mask = tf.keras.utils.load_img(\n",
    "            str(mask_path),\n",
    "            target_size=self.target_size,\n",
    "            color_mode=\"grayscale\",\n",
    "            interpolation=\"nearest\",\n",
    "        )\n",
    "        mask_array = tf.keras.utils.img_to_array(mask, dtype=np.int8)\n",
    "        mask_array = np.vectorize(self.table_id2category.get)(mask_array).squeeze()\n",
    "        if self.label_onehot:\n",
    "            mask_array = tf.keras.utils.to_categorical(\n",
    "                mask_array, num_classes=self.num_classes\n",
    "            )\n",
    "        return mask_array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a397e8d",
   "metadata": {},
   "source": [
    "## 7. Gestion des augmentations de données\n",
    "\n",
    "La méthode `load_and_augment` applique le pipeline d'augmentations (flip, brightness, blur, etc.) sur les images et masques si activé."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88fc8694",
   "metadata": {},
   "outputs": [],
   "source": [
    "    def load_and_augment(\n",
    "        self, paths: Tuple[pathlib.Path, pathlib.Path]\n",
    "    ) -> Union[\n",
    "        Tuple[np.ndarray, np.ndarray], Tuple[np.ndarray, np.ndarray, np.ndarray]\n",
    "    ]:\n",
    "        \"\"\"\n",
    "        Charge image et masque, applique les augmentations et la normalisation si activées.\n",
    "        \"\"\"\n",
    "        img_path, mask_path = paths\n",
    "        img = self.load_img_to_array(img_path)\n",
    "        mask = self.load_mask_to_array(mask_path)\n",
    "\n",
    "        if self.sample_weights is not None:\n",
    "            weights = np.take(self.sample_weights, mask)\n",
    "            if self.augmentations:\n",
    "                augmented = self.compose(image=img, mask=mask, sample_weights=mask)\n",
    "                return (\n",
    "                    augmented[\"image\"],\n",
    "                    augmented[\"mask\"],\n",
    "                    augmented[\"sample_weights\"],\n",
    "                )\n",
    "            else:\n",
    "                return img, mask, weights\n",
    "        else:\n",
    "            if self.augmentations:\n",
    "                augmented = self.compose(image=img, mask=mask)\n",
    "                return augmented[\"image\"], augmented[\"mask\"]\n",
    "            else:\n",
    "                return img, mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6a62664",
   "metadata": {},
   "source": [
    "## 8. Gestion du mélange des données (shuffle)\n",
    "\n",
    "La méthode `on_epoch_end` mélange les chemins images/masques à la fin de chaque époque si l'option shuffle est activée."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb59f775",
   "metadata": {},
   "outputs": [],
   "source": [
    "    def on_epoch_end(self) -> None:\n",
    "        \"\"\"\n",
    "        Mélange le dataset à la fin de chaque époque si shuffle est activé.\n",
    "        \"\"\"\n",
    "        if self.shuffle:\n",
    "            zip_paths = list(zip(self.image_paths, self.mask_paths))\n",
    "            np.random.shuffle(zip_paths)\n",
    "            self.image_paths, self.mask_paths = zip(*zip_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5406f177",
   "metadata": {},
   "source": [
    "## 9. Gestion des batchs et récupération d’un batch\n",
    "\n",
    "La méthode `__len__` retourne le nombre de batchs par époque, et `__getitem__` retourne un batch d'images, masques (et poids si applicable)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "321615d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "    def __len__(self) -> int:\n",
    "        \"\"\"\n",
    "        Retourne le nombre de batchs par époque.\n",
    "        \"\"\"\n",
    "        return math.ceil(self.num_samples / self.batch_size)\n",
    "\n",
    "    def __getitem__(\n",
    "        self, index: int\n",
    "    ) -> Union[\n",
    "        Tuple[np.ndarray, np.ndarray], Tuple[np.ndarray, np.ndarray, np.ndarray]\n",
    "    ]:\n",
    "        \"\"\"\n",
    "        Récupère un batch d'images et de masques à l'index donné.\n",
    "        \"\"\"\n",
    "        start_idx = index * self.batch_size\n",
    "        end_idx = min(start_idx + self.batch_size, self.num_samples)\n",
    "        if start_idx >= self.num_samples:\n",
    "            raise IndexError(\"Index out of range\")\n",
    "\n",
    "        batch_paths = list(\n",
    "            zip(self.image_paths[start_idx:end_idx], self.mask_paths[start_idx:end_idx])\n",
    "        )\n",
    "        results = [self.load_and_augment(pair) for pair in batch_paths]\n",
    "\n",
    "        if self.sample_weights is not None:\n",
    "            images, masks, weights = zip(*results)\n",
    "            return np.asarray(images), np.asarray(masks), np.asarray(weights)\n",
    "        else:\n",
    "            images, masks = zip(*results)\n",
    "            return np.asarray(images), np.asarray(masks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b9f3ec",
   "metadata": {},
   "source": [
    "## 10. Visualisation des transformations\n",
    "\n",
    "La méthode `show_transformation` permet d'afficher l'image et le masque avant/après transformation pour un index donné."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ec354d",
   "metadata": {},
   "outputs": [],
   "source": [
    "    def get_image_and_mask(\n",
    "        self, index: int\n",
    "    ) -> Tuple[np.ndarray, np.ndarray, Tuple[pathlib.Path, pathlib.Path]]:\n",
    "        \"\"\"\n",
    "        Récupère une paire image/masque pour visualisation.\n",
    "        \"\"\"\n",
    "        paths = (self.image_paths[index], self.mask_paths[index])\n",
    "        if self.sample_weights is None:\n",
    "            img, mask = self.load_and_augment(paths)\n",
    "        else:\n",
    "            img, mask, _ = self.load_and_augment(paths)\n",
    "        return img, mask, paths\n",
    "\n",
    "    def show_transformation(\n",
    "        self, index: int, figsize: Tuple[int, int] = (12, 8)\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        Affiche l'image et le masque avant/après transformation pour un index donné.\n",
    "        \"\"\"\n",
    "        img, mask, paths = self.get_image_and_mask(index)\n",
    "        img_path, mask_path = paths\n",
    "\n",
    "        fig, ax = plt.subplots(2, 2, figsize=figsize)\n",
    "        fig.suptitle(\"Image et masque avant/après transformation\", fontsize=16)\n",
    "        ax[0, 0].imshow(plt.imread(img_path))\n",
    "        ax[0, 0].set_title(\"Image originale\")\n",
    "        ax[0, 1].imshow(img)\n",
    "        ax[0, 1].set_title(\"Image transformée\")\n",
    "        ax[1, 0].imshow(plt.imread(mask_path))\n",
    "        ax[1, 0].set_title(\"Masque original\")\n",
    "        ax[1, 1].imshow(mask)\n",
    "        ax[1, 1].set_title(\"Masque transformé\")\n",
    "        for a in ax.ravel():\n",
    "            a.axis(\"off\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea4e29b",
   "metadata": {},
   "source": [
    "## 11. Visualisation des prédictions du modèle\n",
    "\n",
    "La méthode `show_prediction` affiche l'image, le masque réel et la prédiction du modèle pour un index donné."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b71d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "    def get_prediction(self, model: Any, index: int) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Génère une prédiction pour une image donnée à l'aide du modèle fourni.\n",
    "        \"\"\"\n",
    "        img, _, _ = self.get_image_and_mask(index)\n",
    "        mask_pred = model.predict(np.expand_dims(img, axis=0))\n",
    "        mask_pred = np.argmax(mask_pred.squeeze(), axis=-1)\n",
    "        return mask_pred\n",
    "\n",
    "    def show_prediction(\n",
    "        self, model: Any, index: int, figsize: Tuple[int, int] = (15, 6)\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        Affiche l'image, le masque réel et la prédiction du modèle pour un index donné.\n",
    "        \"\"\"\n",
    "        img, mask, paths = self.get_image_and_mask(index)\n",
    "        img_path, mask_path = paths\n",
    "        mask_pred = self.get_prediction(model, index)\n",
    "\n",
    "        fig = plt.figure(layout=\"constrained\", figsize=figsize)\n",
    "        fig.suptitle(f\"{model.name} - Prédiction\", fontsize=16)\n",
    "        subfigs = fig.subfigures(2, 1, wspace=0.07)\n",
    "        axsTop = subfigs[0].subplots(1, 3, sharey=True, sharex=True)\n",
    "        axsBottom = subfigs[1].subplots(1, 3, sharey=True, sharex=True)\n",
    "\n",
    "        for i, ax in enumerate(axsTop):\n",
    "            if i == 0:\n",
    "                ax.imshow(self.load_img_to_array(img_path))\n",
    "                ax.set_title(\"Image originale\")\n",
    "            elif i == 1:\n",
    "                ax.imshow(mask, cmap=\"Greys\")\n",
    "                ax.set_title(\"Masque réel (N&B)\")\n",
    "            else:\n",
    "                ax.imshow(mask)\n",
    "                ax.set_title(\"Masque réel (RGB)\")\n",
    "            ax.axis(\"off\")\n",
    "\n",
    "        for i, ax in enumerate(axsBottom):\n",
    "            if i == 0:\n",
    "                ax.imshow(self.load_img_to_array(img_path))\n",
    "                ax.set_title(\"Image originale\")\n",
    "            elif i == 1:\n",
    "                ax.imshow(mask_pred, cmap=\"Greys\")\n",
    "                ax.set_title(\"Masque prédit (N&B)\")\n",
    "            else:\n",
    "                ax.imshow(mask_pred)\n",
    "                ax.set_title(\"Masque prédit (RGB)\")\n",
    "            ax.axis(\"off\")\n",
    "        plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
